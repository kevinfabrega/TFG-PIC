#OPTIMIZATION OF PARAMETERS USING OPTUNA
#We optimize the model to predict one hour in specific after the drainage (the 8th hour in this case)

time_drop = 8

non_numbered_columns = [col for col in df_check.columns if not str(col).isdigit()]

df_filtered = df_check[non_numbered_columns + [time_drop]]
df_filtered = df_filtered.drop('t', axis = 1)
df_filtered.head(-1)


# ============================
# Data preparation
# ============================

X = df_filtered.iloc[:, :-1]
y = df_filtered.iloc[:, -1]
mask = (~y.isna())

X = X[mask]
y = y[mask]

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

dtrain = xgb.DMatrix(X_train, label=y_train)
dval = xgb.DMatrix(X_val, label=y_val)
dtest = xgb.DMatrix(X_test, label=y_test)

# ============================
# Optuna
# ============================
def objective(trial):
    n_estimators = trial.suggest_int("n_estimators", 500, 5000)
    early_stopping_rounds = trial.suggest_int("early_stopping_rounds", 5, 10)
    
    params = {
        "objective": "reg:squarederror",
        "eval_metric": "rmse",
        "random_state": 42,
        "max_depth": trial.suggest_int("max_depth", 5, 9),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
        "subsample": trial.suggest_float("subsample", 0.7, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.7, 1.0),
        "colsample_bylevel": trial.suggest_float("colsample_bylevel", 0.7, 1.0),
        "alpha": trial.suggest_float("alpha", 0.0, 1.0),
        "lambda": trial.suggest_float("lambda", 0.0, 10.0),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.2),
    }

    model = xgb.train(
        params,
        dtrain,
        num_boost_round=n_estimators,
        evals=[(dval, "validation")],
        early_stopping_rounds=early_stopping_rounds,
        verbose_eval=False
    )

    preds = model.predict(dval)
    r2 = r2_score(y_val, preds)
    return r2

study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=500, show_progress_bar=True)

best_params = study.best_params
print("Best Hyperparameters:", best_params)

# ============================
# Entrenar modelo final
# ============================
num_boost_round = best_params.pop("n_estimators")  # lo sacamos del dict
early_stopping_rounds = best_params.pop("early_stopping_rounds")  # lo sacamos del dict

final_params = {
    "objective": "reg:squarederror",
    "eval_metric": "rmse",
    "random_state": 42,
    **best_params
}

xgb_model = xgb.train(
    final_params,
    dtrain,
    num_boost_round=num_boost_round,
    evals=[(dtrain, 'train'), (dval, 'validation')],
    early_stopping_rounds=early_stopping_rounds,
    verbose_eval=False
)

print("Model trained")

# ============================
# Validación cruzada final
# ============================
dtrain_all = xgb.DMatrix(X, label=y)
cv_results = xgb.cv(
    params=final_params,
    dtrain=dtrain_all,
    num_boost_round=num_boost_round,
    nfold=5,
    metrics={"rmse"},
    early_stopping_rounds=early_stopping_rounds,
    seed=42,
    verbose_eval=False,
    as_pandas=True
)

best_cv_rmse_std = cv_results["test-rmse-std"].iloc[-1]
print("Kfold:", best_cv_rmse_std)

# ============================
# Métricas finales
# ============================
train_preds = xgb_model.predict(dtrain)
val_preds = xgb_model.predict(dval)
test_preds = xgb_model.predict(dtest)

train_r2 = r2_score(y_train, train_preds)
val_r2 = r2_score(y_val, val_preds)
test_r2 = r2_score(y_test, test_preds)

train_mse = mean_squared_error(y_train, train_preds)
val_mse = mean_squared_error(y_val, val_preds)
test_mse = mean_squared_error(y_test, test_preds)

print(f"Train R²: {train_r2:.4f}, Train MSE: {train_mse:.4f}")
print(f"Validation R²: {val_r2:.4f}, Validation MSE: {val_mse:.4f}")
print(f"Test R²: {test_r2:.4f}, Test MSE: {test_mse:.4f}")


# ============================
# Feature Importance
# ============================
# Graficar importancia de las features
booster = xgb_model  # `xgb.train` devuelve un booster directamente
fig, ax = plt.subplots(figsize=(14, 10))
xgb.plot_importance(booster, importance_type='gain', show_values=False, ax=ax)
plt.title("Feature Importance (gain)")
plt.tight_layout()
plt.show()




# TRAINING THE MODEL WITH THE BEST HYPERPARAMETERS OBTAINED

fig = plt.figure(figsize=(8,8))
times = np.arange(1, 51)

train_rmse_a = []
train_r2_a = []
val_rmse_a = []
val_r2_a = []
test_rmse_a = []
test_r2_a = []
val_rmse_kfold_std_list = []
feature_importance_list = []
val_r2_kfold_std_error_list = [] 

params = {
    "objective": "reg:squarederror",
    "eval_metric": "rmse",
    "seed": 42,
    "n_jobs": -1,
    
    "max_depth": 8, 
    "min_child_weight": 1, 
    'subsample': 0.9456575365804781,             # [0.7, 1.0)
    'colsample_bytree': 0.9533019606433565,      # [0.7, 1.0)
    'colsample_bylevel': 0.8512748801343423,     # [0.7, 1.0)
    'alpha': 0.054527256868301954,                     # [0.0, 1.0)
    'lambda': 7.009876185195353,                    # [1.0, 10.0)               
    'learning_rate': 0.11756231094174867         # [0.01, 0.2)
    }

df_importance = pd.DataFrame()
if os.path.exists("./df_importance_xgboost_8h_f.pkl"):
    df_importance = pd.read_pickle("./df_importance_xgboost_8h_f.pkl")
    print("Importancias previamente guardadas:", df_importance.shape[1], "time_drops")
    
df_xgboost = pd.DataFrame()

if os.path.exists("./df_metrics_xgboost_8h_f.pkl"):
    df_xgboost = pd.read_pickle("./df_metrics_xgboost_8h_f.pkl")
    procesados = set(df_xgboost['time_drop']) if 'time_drop' in df_xgboost.columns else set()
    print(f"Reanudando. Ya procesados: {sorted(procesados)}")
else:
    procesados = set()
    print("Comenzando desde cero.")

plt_c = 1

kf = KFold(n_splits=10, shuffle=True, random_state=42)

for time_drop in times:
    if time_drop in procesados:
        continue

    print("Time: ", time_drop)
    non_numbered_columns = [col for col in df_check.columns if not str(col).isdigit()]
    df_filtered = df_check[non_numbered_columns + [time_drop]]

    print("->", df_filtered.shape[0])
    df_filtered = df_filtered.drop('t', axis=1)
    print("<-", df_filtered.shape[0])

    nc = df_filtered.shape[1]
    X = df_filtered.iloc[:, :nc-1]
    y = df_filtered.iloc[:, nc-1]
    mask = (~y.isna())

    X = X[mask]
    y = y[mask]

    if len(y) == 0:
        print(f"Time drop {time_drop} descartado: todos los valores de 'y' inválidos.")
        continue

    # ===> CALCULO MANUAL DEL CROSS VALIDATION
    kf = KFold(n_splits=10, shuffle=True, random_state=42)
    r2_fold_scores = []

    for train_index, val_index in kf.split(X):
        X_train_cv, X_val_cv = X.iloc[train_index], X.iloc[val_index]
        y_train_cv, y_val_cv = y.iloc[train_index], y.iloc[val_index]

        dtrain_cv = xgb.DMatrix(X_train_cv, label=y_train_cv)
        dval_cv = xgb.DMatrix(X_val_cv, label=y_val_cv)

        model_cv = xgb.train(
            params=params,
            dtrain=dtrain_cv,
            num_boost_round=3413,
            evals=[(dval_cv, "validation")],
            callbacks=[EarlyStopping(rounds=8, metric_name="rmse", data_name="validation", save_best=True)],
            verbose_eval=False
        )

        preds_cv = model_cv.predict(dval_cv)
        r2_cv = r2_score(y_val_cv, preds_cv)
        r2_fold_scores.append(r2_cv)

    # ===> CÁLCULOS DE LOS ERRORES
    r2_fold_scores = np.array(r2_fold_scores)
    sigma_r2 = np.std(r2_fold_scores)
    mean_r2 = np.mean(r2_fold_scores)
    
    error_estandar_r2 = sigma_r2 / np.sqrt(10)          #esto es lo nuevo que habías pedido
    kfold_std_percentage = (sigma_r2 / mean_r2) * 100   #esto es lo que quieres ahora en 'kfold std'

    print(f"Kfold % error: {kfold_std_percentage:.4f}")
    print(f"Kfold error estándar: {error_estandar_r2:.6f}")

    val_rmse_kfold_std_list.append(kfold_std_percentage)

    # ===> SPLITS NORMAL TRAIN-VAL-TEST
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dval = xgb.DMatrix(X_val, label=y_val)

    xgb_model = xgb.train(
        params=params,
        dtrain=dtrain,
        num_boost_round=3413,
        evals=[(dval, "validation")],
        callbacks=[EarlyStopping(rounds=8, metric_name="rmse", data_name="validation", save_best=True)],
        verbose_eval=False
    )

    train_preds = xgb_model.predict(dtrain)
    train_r2 = r2_score(y_train, train_preds)
    train_rmse = root_mean_squared_error(y_train, train_preds)

    eval_preds = xgb_model.predict(dval)
    eval_r2 = r2_score(y_val, eval_preds)
    eval_rmse = root_mean_squared_error(y_val, eval_preds)

    dtest = xgb.DMatrix(X_test, label=y_test)
    test_preds = xgb_model.predict(dtest)
    test_r2 = r2_score(y_test, test_preds)
    test_rmse = root_mean_squared_error(y_test, test_preds)

    print("test r2:", test_r2)

    importance_dict = xgb_model.get_score(importance_type='gain')
    importance_df = pd.DataFrame.from_dict(importance_dict, orient='index', columns=['importance'])
    importance_df = importance_df.reindex(X.columns, fill_value=0)

    df_importance[time_drop] = importance_df['importance'].values
    df_importance.index = importance_df.index
    df_importance.to_pickle("./df_importance_xgboost_8h_f.pkl")

    if time_drop <= 12:
        plt.subplot(3, 4, plt_c)
        plt.plot(y_test, test_preds, '.', markersize=0.5, alpha=1)
        plt.xlim(0,1)
        plt.ylim(0,1)
        plt.plot([0,1], [0,1], 'k--')
        plt.title(f"{time_drop}h since drainage")
        plt.xlabel("used cores reduction factor")
        plt.ylabel("Prediction XGBoost")
        plt.tight_layout()
        plt_c += 1

    # ===> GUARDADO
    new_row = pd.DataFrame([{
        'time_drop': time_drop,
        'test r2': test_r2,
        'test rmse': test_rmse,
        'validation r2': eval_r2,
        'validation rmse': eval_rmse,
        'train r2': train_r2,
        'train rmse': train_rmse,
        'kfold std perc': kfold_std_percentage,      
        'kfold r2 error': error_estandar_r2,       
    }])

    df_xgboost = pd.concat([df_xgboost, new_row], ignore_index=True)
    df_xgboost.to_pickle("./df_metrics_xgboost_8h_f.pkl")

plt.show()
